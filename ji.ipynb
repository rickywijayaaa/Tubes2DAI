{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>URL</th>\n",
       "      <th>URLLength</th>\n",
       "      <th>Domain</th>\n",
       "      <th>DomainLength</th>\n",
       "      <th>IsDomainIP</th>\n",
       "      <th>TLD</th>\n",
       "      <th>CharContinuationRate</th>\n",
       "      <th>TLDLegitimateProb</th>\n",
       "      <th>...</th>\n",
       "      <th>Pay</th>\n",
       "      <th>Crypto</th>\n",
       "      <th>HasCopyrightInfo</th>\n",
       "      <th>NoOfImage</th>\n",
       "      <th>NoOfCSS</th>\n",
       "      <th>NoOfJS</th>\n",
       "      <th>NoOfSelfRef</th>\n",
       "      <th>NoOfEmptyRef</th>\n",
       "      <th>NoOfExternalRef</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.northcm.ac.th</td>\n",
       "      <td>24.0</td>\n",
       "      <td>www.northcm.ac.th</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>8135291.txt</td>\n",
       "      <td>http://uqr.to/1il1z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>586561.txt</td>\n",
       "      <td>https://www.woolworthsrewards.com.au</td>\n",
       "      <td>35.0</td>\n",
       "      <td>www.woolworthsrewards.com.au</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>au</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>com</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.522907</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>412632.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>www.nyprowrestling.com</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140399</th>\n",
       "      <td>235790</td>\n",
       "      <td>49490.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>www.slavevoyages.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079963</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140400</th>\n",
       "      <td>235791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.greenmountainenergy.com</td>\n",
       "      <td>34.0</td>\n",
       "      <td>www.greenmountainenergy.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>com</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522907</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140401</th>\n",
       "      <td>235792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.leadcastingcall.com</td>\n",
       "      <td>30.0</td>\n",
       "      <td>www.leadcastingcall.com</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140402</th>\n",
       "      <td>235794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.fedarb.com</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140403</th>\n",
       "      <td>235795</td>\n",
       "      <td>464776.txt</td>\n",
       "      <td>https://www.risenenergy.com</td>\n",
       "      <td>26.0</td>\n",
       "      <td>www.risenenergy.com</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140404 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     FILENAME                                   URL  URLLength  \\\n",
       "0            1          NaN             https://www.northcm.ac.th       24.0   \n",
       "1            4  8135291.txt                   http://uqr.to/1il1z        NaN   \n",
       "2            5   586561.txt  https://www.woolworthsrewards.com.au       35.0   \n",
       "3            6          NaN                                   NaN       31.0   \n",
       "4           11   412632.txt                                   NaN        NaN   \n",
       "...        ...          ...                                   ...        ...   \n",
       "140399  235790    49490.txt                                   NaN        NaN   \n",
       "140400  235791          NaN   https://www.greenmountainenergy.com       34.0   \n",
       "140401  235792          NaN       https://www.leadcastingcall.com       30.0   \n",
       "140402  235794          NaN                https://www.fedarb.com       21.0   \n",
       "140403  235795   464776.txt           https://www.risenenergy.com       26.0   \n",
       "\n",
       "                              Domain  DomainLength  IsDomainIP  TLD  \\\n",
       "0                  www.northcm.ac.th          17.0         0.0  NaN   \n",
       "1                                NaN           NaN         NaN   to   \n",
       "2       www.woolworthsrewards.com.au          28.0         0.0   au   \n",
       "3                                NaN           NaN         NaN  com   \n",
       "4             www.nyprowrestling.com          22.0         0.0  NaN   \n",
       "...                              ...           ...         ...  ...   \n",
       "140399          www.slavevoyages.org           NaN         0.0  NaN   \n",
       "140400   www.greenmountainenergy.com           NaN         0.0  com   \n",
       "140401       www.leadcastingcall.com          23.0         NaN  NaN   \n",
       "140402                           NaN          14.0         NaN  NaN   \n",
       "140403           www.risenenergy.com          19.0         NaN  NaN   \n",
       "\n",
       "        CharContinuationRate  TLDLegitimateProb  ...  Pay  Crypto  \\\n",
       "0                   0.800000                NaN  ...  0.0     0.0   \n",
       "1                   1.000000           0.000896  ...  NaN     0.0   \n",
       "2                   0.857143                NaN  ...  1.0     0.0   \n",
       "3                   0.562500           0.522907  ...  1.0     0.0   \n",
       "4                   1.000000                NaN  ...  0.0     0.0   \n",
       "...                      ...                ...  ...  ...     ...   \n",
       "140399              1.000000           0.079963  ...  NaN     0.0   \n",
       "140400              1.000000           0.522907  ...  1.0     NaN   \n",
       "140401              1.000000           0.522907  ...  0.0     0.0   \n",
       "140402              1.000000           0.522907  ...  0.0     0.0   \n",
       "140403              1.000000           0.522907  ...  0.0     0.0   \n",
       "\n",
       "        HasCopyrightInfo  NoOfImage  NoOfCSS  NoOfJS  NoOfSelfRef  \\\n",
       "0                    1.0        NaN      3.0     NaN         69.0   \n",
       "1                    0.0        NaN      NaN     NaN          NaN   \n",
       "2                    1.0       33.0      7.0     8.0         15.0   \n",
       "3                    1.0       24.0      5.0    14.0          NaN   \n",
       "4                    1.0        NaN      NaN    14.0          NaN   \n",
       "...                  ...        ...      ...     ...          ...   \n",
       "140399               1.0       23.0      3.0     6.0          NaN   \n",
       "140400               1.0       26.0      NaN     NaN        169.0   \n",
       "140401               1.0       25.0      NaN     NaN         87.0   \n",
       "140402               1.0        NaN     36.0     NaN        102.0   \n",
       "140403               NaN       34.0      3.0     3.0        126.0   \n",
       "\n",
       "        NoOfEmptyRef  NoOfExternalRef  label  \n",
       "0                NaN              NaN      1  \n",
       "1                NaN              1.0      0  \n",
       "2                NaN              2.0      1  \n",
       "3                NaN              NaN      1  \n",
       "4                0.0              NaN      1  \n",
       "...              ...              ...    ...  \n",
       "140399          12.0              NaN      1  \n",
       "140400          15.0             40.0      1  \n",
       "140401           1.0             93.0      1  \n",
       "140402           NaN              NaN      1  \n",
       "140403           3.0            129.0      1  \n",
       "\n",
       "[140404 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying float columns (0, 1, or NaN)\n",
    "binary_float_features = df.select_dtypes(include=['float']).columns\n",
    "binary_like_features = binary_float_features[df[binary_float_features].isin([0, 1, float('nan')]).all()]\n",
    "\n",
    "# Categorical columns + binary-like float columns\n",
    "categorical_features = df.select_dtypes(include=['object', 'category']).columns\n",
    "all_categorical_features = list(binary_like_features) + list(categorical_features)\n",
    "\n",
    "all_categorical_features = [feature for feature in all_categorical_features if feature not in ['NoOfURLRedirect', 'NoOfSelfRedirect','FILENAME','URL', 'Domain', 'Title']]\n",
    "all_categorical_features.append('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_features = ['FILENAME', 'URL', 'Domain',  'Title', 'id']\n",
    "numerical_features = [feature for feature in df.columns.difference(all_categorical_features) if feature not in exclude_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features = ['FILENAME', 'URL', 'Domain', 'Title', 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_df = pd.DataFrame(all_categorical_features, columns=['Categorical Features'])\n",
    "categorical_features_df.index = range(1, len(categorical_features_df) + 1)\n",
    "\n",
    "numerical_features_df = pd.DataFrame(numerical_features, columns=['Numerical Features'])\n",
    "numerical_features_df.index = range(1, len(numerical_features_df) + 1)\n",
    "\n",
    "text_features_df = pd.DataFrame(discrete_features, columns=['Text Features'])\n",
    "text_features_df.index = range(1, len(text_features_df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categorical Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IsDomainIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HasObfuscation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IsHTTPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HasTitle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HasFavicon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Robots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IsResponsive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HasDescription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HasExternalFormSubmit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HasSocialNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HasSubmitButton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HasHiddenFields</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HasPasswordField</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Crypto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HasCopyrightInfo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Categorical Features\n",
       "1              IsDomainIP\n",
       "2          HasObfuscation\n",
       "3                 IsHTTPS\n",
       "4                HasTitle\n",
       "5              HasFavicon\n",
       "6                  Robots\n",
       "7            IsResponsive\n",
       "8          HasDescription\n",
       "9   HasExternalFormSubmit\n",
       "10           HasSocialNet\n",
       "11        HasSubmitButton\n",
       "12        HasHiddenFields\n",
       "13       HasPasswordField\n",
       "14                   Bank\n",
       "15                    Pay\n",
       "16                 Crypto\n",
       "17       HasCopyrightInfo\n",
       "18                    TLD\n",
       "19                  label"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Save original training set\n",
    "train_set_ori = df.copy()\n",
    "\n",
    "# Split training set and validation set\n",
    "train_set, val_set  = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleLength(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting process needed\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Copy the DataFrame to avoid modifying the original\n",
    "        X_transformed = X.copy()\n",
    "        \n",
    "        # Drop rows where URL is completely NaN\n",
    "        X_transformed = X_transformed.dropna(subset=['URL'])\n",
    "        \n",
    "        # Impute Domain using URL if Domain is NaN\n",
    "        def extract_domain(url):\n",
    "            try:\n",
    "                parsed_url = urlparse(url)\n",
    "                return parsed_url.netloc if parsed_url.netloc else None\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        X_transformed['Domain'] = X_transformed.apply(\n",
    "            lambda row: extract_domain(row['URL']) if pd.isna(row['Domain']) else row['Domain'], axis=1\n",
    "        )\n",
    "        \n",
    "        # Fill URLLength with the lengths of URL strings\n",
    "        X_transformed['URLLength'] = X_transformed['URL'].apply(lambda x: len(str(x)) if pd.notna(x) else None)\n",
    "        \n",
    "        # Fill DomainLength with the lengths of Domain strings\n",
    "        X_transformed['DomainLength'] = X_transformed['Domain'].apply(lambda x: len(str(x)) if pd.notna(x) else None)\n",
    "        \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleIsHTTPS(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting process needed\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Copy the DataFrame to avoid modifying the original\n",
    "        X_transformed = X.copy()\n",
    "        \n",
    "        # Drop rows where URL is completely NaN\n",
    "        X_transformed = X_transformed.dropna(subset=['URL'])\n",
    "        \n",
    "        # Check if the URL contains HTTPS\n",
    "        X_transformed['IsHTTPS'] = X_transformed['URL'].apply(\n",
    "            lambda x: 1 if pd.notna(x) and urlparse(x).scheme.lower() == 'https' else 0\n",
    "        )\n",
    "        \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class HandleCharContinuationRate(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting process needed\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Copy the DataFrame to avoid modifying the original\n",
    "        X_transformed = X.copy()\n",
    "        \n",
    "        # Function to calculate CharContinuationRate\n",
    "        def calculate_char_cont_rate(url):\n",
    "            if not isinstance(url, str):\n",
    "                return None  # Return None for invalid URLs\n",
    "            \n",
    "            # Find all alphabet, digit, or special character sequences\n",
    "            sequences = re.findall(r'[a-zA-Z]+|\\d+|[^a-zA-Z\\d]+', url)\n",
    "            \n",
    "            # Calculate total length of sequences\n",
    "            total_sequence_length = sum(len(seq) for seq in sequences)\n",
    "            \n",
    "            # Return the CharContinuationRate\n",
    "            return total_sequence_length / len(url) if len(url) > 0 else 0\n",
    "\n",
    "        # Impute missing CharContinuationRate values\n",
    "        X_transformed['CharContinuationRate'] = X_transformed['CharContinuationRate'].fillna(\n",
    "            X_transformed['URL'].apply(lambda x: calculate_char_cont_rate(x))\n",
    "        )\n",
    "        \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleHasTitle(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting process needed\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Copy the DataFrame to avoid modifying the original\n",
    "        X_transformed = X.copy()\n",
    "        \n",
    "        # Create HasTitle column: 1 if Title is not NaN, 0 otherwise\n",
    "        X_transformed['HasTitle'] = X_transformed['Title'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "        \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class HandleURLTitleMatchScore(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # No fitting process needed\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        X_transformed = X.copy()\n",
    "    \n",
    "        def url_title_match_score(title, url):\n",
    "            if not isinstance(title, str) or not isinstance(url, str):\n",
    "                return None  # Return None for invalid inputs\n",
    "            \n",
    "            # Split the title into a set of words\n",
    "            t_set = title.split()\n",
    "            \n",
    "            # Clean the URL (remove https, http, www, and extract root domain)\n",
    "            clean_url = re.sub(r'https?://|www\\.', '', url).split('/')[0]  # Keep root domain\n",
    "            \n",
    "            # Compute baseScore\n",
    "            base_score = 100 / len(clean_url) if len(clean_url) > 0 else 0\n",
    "            \n",
    "            # Calculate score\n",
    "            score = 0\n",
    "            for word in t_set:\n",
    "                if word in clean_url:\n",
    "                    score += base_score * len(word)\n",
    "                    clean_url = clean_url.replace(word, \"\")  # Remove matched word from URL\n",
    "                if score > 99.9:\n",
    "                    score = 100\n",
    "                    break\n",
    "            \n",
    "            return score\n",
    "        \n",
    "        X_transformed['URLTitleMatchScore'] = X_transformed['URLTitleMatchScore'].fillna(\n",
    "            X_transformed.apply(\n",
    "                lambda row: url_title_match_score(row['Title'], row['URL']), axis=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "class FeatureImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # Separate columns by type\n",
    "        self.categorical_cols = ['TLD', 'Domain', 'FILENAME', 'URL', 'Title']\n",
    "        self.boolean_cols = [\n",
    "            'IsDomainIP', 'HasObfuscation', 'IsHTTPS', 'HasTitle', 'HasFavicon',\n",
    "            'Robots', 'IsResponsive', 'NoOfURLRedirect', 'NoOfSelfRedirect', 'HasDescription',\n",
    "            'HasExternalFormSubmit', 'HasSocialNet', 'HasSubmitButton', 'HasHiddenFields',\n",
    "            'HasPasswordField', 'Bank', 'Pay', 'Crypto', 'HasCopyrightInfo'\n",
    "        ]\n",
    "        self.numerical_cols = list(set(X.columns) - set(self.categorical_cols) - set(self.boolean_cols))\n",
    "        \n",
    "        # Imputer for categorical columns (most frequent)\n",
    "        self.cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        self.cat_imputer.fit(X[self.categorical_cols])\n",
    "        \n",
    "        # Imputer for boolean columns (mode)\n",
    "        self.bool_mode_imputer = {}\n",
    "        for col in self.boolean_cols:\n",
    "            self.bool_mode_imputer[col] = X[col].mode()[0]\n",
    "        \n",
    "        # KNN Imputer for numerical columns\n",
    "        self.knn_imputer = IterativeImputer(estimator=DecisionTreeRegressor(random_state=42))\n",
    "        self.knn_imputer.fit(X[self.numerical_cols])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_imputed = X.copy()\n",
    "\n",
    "        # Impute categorical columns\n",
    "        X_imputed[self.categorical_cols] = self.cat_imputer.transform(X_imputed[self.categorical_cols])\n",
    "\n",
    "        # Impute boolean columns using pre-calculated mode\n",
    "        for col in self.boolean_cols:\n",
    "            X_imputed[col].fillna(self.bool_mode_imputer[col], inplace=True)\n",
    "            \n",
    "        # Impute numerical columns using KNNImputer\n",
    "        X_imputed[self.numerical_cols] = self.knn_imputer.transform(X_imputed[self.numerical_cols])\n",
    "        \n",
    "        return X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_to_drop):\n",
    "        self.features_to_drop = features_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Drop the specified features\n",
    "        X_dropped = X.drop(columns=self.features_to_drop, errors='ignore')\n",
    "        return X_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_TO_DROP = [\n",
    "    'Domain', 'TLD', 'FILENAME', 'URL', 'Title', 'TLD'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([ (\"length\", HandleLength()),\n",
    "                      (\"https\", HandleIsHTTPS()),\n",
    "                      (\"title\", HandleHasTitle()),\n",
    "                      #(\"char\", HandleCharContinuationRate()),\n",
    "                      (\"urltitle\", HandleURLTitleMatchScore()),\n",
    "                      (\"imputer\", FeatureImputer()),\n",
    "                      (\"dropper\", FeatureDropper(FEATURES_TO_DROP)),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jihan Aurelia\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_set = pipeline.fit_transform(train_set)\n",
    "val_set = pipeline.transform(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def classify_categorical_features(data):\n",
    "    \"\"\"\n",
    "    Classify categorical features, including binary-like float columns.\n",
    "    \"\"\"\n",
    "    # Identify float columns (0, 1, or NaN)\n",
    "    binary_float_features = data.select_dtypes(include=['float']).columns\n",
    "    binary_like_features = [\n",
    "        col for col in binary_float_features \n",
    "        if data[col].dropna().isin([0, 1]).all()\n",
    "    ]\n",
    "\n",
    "    # Identify categorical columns\n",
    "    categorical_features = data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    # Combine binary-like float and categorical columns\n",
    "    all_categorical_features = list(binary_like_features) + list(categorical_features)\n",
    "\n",
    "    # Exclude specific columns\n",
    "    excluded_columns = ['NoOfURLRedirect', 'NoOfSelfRedirect', 'FILENAME', 'URL', 'Domain', 'Title']\n",
    "    all_categorical_features = [\n",
    "        feature for feature in all_categorical_features if feature not in excluded_columns\n",
    "    ]\n",
    "\n",
    "    # Ensure the label column is included\n",
    "    all_categorical_features.append('label')\n",
    "\n",
    "    return all_categorical_features\n",
    "\n",
    "def handle_outliers(data, method=\"iterative\", estimator=None):\n",
    "    \"\"\"\n",
    "    Handle outliers in numerical columns, excluding categorical columns.\n",
    "    \"\"\"\n",
    "    if method == \"iterative\" and estimator is None:\n",
    "        # Default estimator for Iterative Imputer\n",
    "        estimator = BayesianRidge()\n",
    "\n",
    "    # Identify categorical features\n",
    "    categorical_features = classify_categorical_features(data)\n",
    "\n",
    "    # Process only numerical columns that are not categorical\n",
    "    numerical_columns = [\n",
    "        col for col in data.select_dtypes(include=['int64', 'float64']).columns \n",
    "        if col not in categorical_features\n",
    "    ]\n",
    "\n",
    "    for col in numerical_columns:\n",
    "        if data[col].nunique() > 2:\n",
    "            # Detect outliers using IQR\n",
    "            q25, q75 = np.percentile(data[col].dropna(), 25), np.percentile(data[col].dropna(), 75)\n",
    "            iqr = q75 - q25\n",
    "            cut_off = iqr * 1.5\n",
    "            lower, upper = q25 - cut_off, q75 + cut_off\n",
    "\n",
    "            # Mark outliers as NaN\n",
    "            data.loc[(data[col] < lower) | (data[col] > upper), col] = np.nan\n",
    "\n",
    "            # Handle missing values using the chosen method\n",
    "            if method == \"iterative\":\n",
    "                imputer = IterativeImputer(estimator=estimator, random_state=42)\n",
    "                data[[col]] = imputer.fit_transform(data[[col]])\n",
    "            elif method == \"median\":\n",
    "                data[col].fillna(data[col].median(), inplace=True)\n",
    "            else:\n",
    "                data[col].dropna(inplace=True)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = handle_outliers(train_set.copy(), method=\"iterative\", estimator=DecisionTreeRegressor(random_state=42))\n",
    "val_set = handle_outliers(val_set.copy(), method=\"iterative\", estimator=DecisionTreeRegressor(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dropping duplicates: 77628\n",
      "Rows after dropping duplicates: 77628\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows before dropping duplicates:\", len(train_set))\n",
    "train_set.drop_duplicates(inplace=True)\n",
    "print(\"Rows after dropping duplicates:\", len(train_set))\n",
    "\n",
    "train_set.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FEATURES_TO_DROP2 = [\n",
    "'NoOfLettersInURL', \n",
    "'DomainLength', \n",
    "'DomainTitleMatchScore',\n",
    "'CharContinuationRate',\n",
    "'TLDLength',\n",
    "'TLDLegitimateProb',\n",
    "\"NoOfSubDomain\",\n",
    "'NoOfObfuscatedChar',\n",
    "\"ObfuscationRatio\",\n",
    "'NoOfDegitsInURL',\n",
    "'DegitRatioInURL',\n",
    "'NoOfEqualsInURL',\n",
    "'NoOfQMarkInURL',\n",
    "'NoOfAmpersandInURL',\n",
    "'NoOfPopUp'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['IsHighURLMatchScore'] = train_set['URLTitleMatchScore'].apply(lambda x: 1 if x > 20 else 0)\n",
    "val_set['IsHighURLMatchScore'] = val_set['URLTitleMatchScore'].apply(lambda x: 1 if x > 20 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            float64\n",
       "URLLength                     float64\n",
       "DomainLength                  float64\n",
       "IsDomainIP                    float64\n",
       "CharContinuationRate          float64\n",
       "TLDLegitimateProb             float64\n",
       "URLCharProb                   float64\n",
       "TLDLength                     float64\n",
       "NoOfSubDomain                 float64\n",
       "HasObfuscation                float64\n",
       "NoOfObfuscatedChar            float64\n",
       "ObfuscationRatio              float64\n",
       "NoOfLettersInURL              float64\n",
       "LetterRatioInURL              float64\n",
       "NoOfDegitsInURL               float64\n",
       "DegitRatioInURL               float64\n",
       "NoOfEqualsInURL               float64\n",
       "NoOfQMarkInURL                float64\n",
       "NoOfAmpersandInURL            float64\n",
       "NoOfOtherSpecialCharsInURL    float64\n",
       "SpacialCharRatioInURL         float64\n",
       "IsHTTPS                         int64\n",
       "LineOfCode                    float64\n",
       "LargestLineLength             float64\n",
       "HasTitle                        int64\n",
       "DomainTitleMatchScore         float64\n",
       "URLTitleMatchScore            float64\n",
       "HasFavicon                    float64\n",
       "Robots                        float64\n",
       "IsResponsive                  float64\n",
       "NoOfURLRedirect               float64\n",
       "NoOfSelfRedirect              float64\n",
       "HasDescription                float64\n",
       "NoOfPopup                     float64\n",
       "NoOfiFrame                    float64\n",
       "HasExternalFormSubmit         float64\n",
       "HasSocialNet                  float64\n",
       "HasSubmitButton               float64\n",
       "HasHiddenFields               float64\n",
       "HasPasswordField              float64\n",
       "Bank                          float64\n",
       "Pay                           float64\n",
       "Crypto                        float64\n",
       "HasCopyrightInfo              float64\n",
       "NoOfImage                     float64\n",
       "NoOfCSS                       float64\n",
       "NoOfJS                        float64\n",
       "NoOfSelfRef                   float64\n",
       "NoOfEmptyRef                  float64\n",
       "NoOfExternalRef               float64\n",
       "label                         float64\n",
       "IsHighURLMatchScore             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class FeatureScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scaler = RobustScaler()\n",
    "        self.num_columns = None \n",
    "        self.url_title_column = 'URLTitleMatchScore'\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Identify numerical columns excluding the 'URLTitleMatchScore' column and columns with nunique=2\n",
    "        self.num_columns = [\n",
    "            col for col in X.select_dtypes(include=['int64', 'float64']).columns\n",
    "            if col != self.url_title_column and X[col].nunique() > 2\n",
    "        ]\n",
    "        \n",
    "        # Fit the RobustScaler to the numerical columns\n",
    "        self.scaler.fit(X[self.num_columns])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Copy the DataFrame to avoid modifying the original\n",
    "        X_transformed = X.copy()\n",
    "        \n",
    "        # Apply RobustScaler to the numerical columns\n",
    "        if self.num_columns:  # Ensure there are columns to scale\n",
    "            X_transformed[self.num_columns] = self.scaler.transform(X[self.num_columns])\n",
    "        \n",
    "        # Apply Log Transformation to 'URLTitleMatchScore'\n",
    "        if self.url_title_column in X_transformed.columns:\n",
    "            X_transformed[self.url_title_column] = X_transformed[self.url_title_column].apply(\n",
    "                lambda x: np.log1p(x) if pd.notna(x) and x >= 0 else np.nan\n",
    "            )\n",
    "        \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def balance_classes(X_t, y_t):\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_t_res, y_t_res = sm.fit_resample(X_t, y_t)\n",
    "    return X_t_res, y_t_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "class PCATransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components=None):\n",
    "        self.n_components = n_components\n",
    "        self.pca = PCA(n_components=self.n_components)\n",
    "        self.num_columns = None\n",
    "        self.pca_columns = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Identify numerical columns\n",
    "        numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "        \n",
    "        # Filter for continuous columns (unique values > 2)\n",
    "        self.num_columns = [col for col in numerical_cols if X[col].nunique() > 2]\n",
    "        \n",
    "        # Fit PCA on the selected numerical columns\n",
    "        self.pca.fit(X[self.num_columns])\n",
    "        \n",
    "        # Create column names for PCA components\n",
    "        self.pca_columns = [f'PCA_{i+1}' for i in range(self.pca.n_components_)]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Apply PCA transformation to the selected columns and return the modified DataFrame.\n",
    "        \"\"\"\n",
    "        X_transformed = X.copy()\n",
    "        \n",
    "        # Apply PCA to the selected numerical columns\n",
    "        pca_result = self.pca.transform(X[self.num_columns])\n",
    "        \n",
    "        # Create a DataFrame for PCA components\n",
    "        pca_df = pd.DataFrame(pca_result, columns=self.pca_columns, index=X.index)\n",
    "        \n",
    "        # Drop the original numerical columns and concatenate PCA components\n",
    "        X_transformed = X_transformed.drop(columns=self.num_columns, errors='ignore')\n",
    "        X_transformed = pd.concat([X_transformed, pca_df], axis=1)\n",
    "        \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Note: You can add or delete preprocessing components from this pipeline\n",
    "\n",
    "pipe = Pipeline([(\"pca\", PCATransformer()),\n",
    "                (\"dropper\",FeatureDropper(FEATURES_TO_DROP2)),\n",
    "                 (\"scaler\", FeatureScaler()),\n",
    "])\n",
    "\n",
    "train_set = pipe.fit_transform(train_set)\n",
    "val_set = pipe.transform(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_columns(train, test):\n",
    "    # Get list of columns in training set\n",
    "    train_cols = train.columns.tolist()\n",
    "    \n",
    "    # Get list of columns in test set\n",
    "    test_cols = test.columns.tolist()\n",
    "    \n",
    "    # Remove any columns in test set that aren't in training set\n",
    "    for col in test_cols:\n",
    "        if col not in train_cols:\n",
    "            test = test.drop(col, axis=1)\n",
    "    \n",
    "    # Add any missing columns to test set and fill with 0\n",
    "    for col in train_cols:\n",
    "        if col not in test_cols:\n",
    "            test[col] = 0\n",
    "    \n",
    "    # Reorder columns in test set to match training set\n",
    "    test = test[train_cols]\n",
    "    \n",
    "    # Return modified test set\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the columns\n",
    "val_set = match_columns(train_set, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.columns = train_set.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = train_set.drop(['label'], axis=1)\n",
    "y_train = train_set['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform resampling\n",
    "X_train, y_train = balance_classes(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = val_set.drop(['label'], axis=1)\n",
    "y_test = val_set['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"X_train_clean.csv\"  # Nama file output\n",
    "X_train.to_csv(output_path, index=False) \n",
    "\n",
    "output_path = \"y_train_clean.csv\"  # Nama file output\n",
    "y_train.to_csv(output_path, index=False) \n",
    "\n",
    "output_path = \"X_test_clean.csv\"  # Nama file output\n",
    "X_test.to_csv(output_path, index=False) \n",
    "\n",
    "output_path = \"y_test_clean.csv\"  # Nama file output\n",
    "y_test.to_csv(output_path, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = pd.read_csv('X_train_clean.csv')\n",
    "y_train_clean = pd.read_csv('y_train_clean.csv')\n",
    "X_test_clean = pd.read_csv('X_test_clean.csv')\n",
    "y_test_clean = pd.read_csv('y_test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3, metric='mixed', p=1):\n",
    "        \"\"\"\n",
    "        metric='mixed' handles both numerical and categorical data.\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.p = p\n",
    "\n",
    "    def fit(self, X, y, categorical_mask=None):\n",
    "        \"\"\"\n",
    "        Fit the model with training data and labels.\n",
    "        Parameters:\n",
    "        - categorical_mask: A boolean array where True indicates a categorical column.\n",
    "        \"\"\"\n",
    "        self.X_train = np.array(X, dtype=object)\n",
    "        self.y_train = np.array(y, dtype=np.int32)\n",
    "\n",
    "        if categorical_mask is None:\n",
    "            self.categorical_mask = np.array([isinstance(v, str) for v in X.iloc[0]])\n",
    "        else:\n",
    "            self.categorical_mask = np.array(categorical_mask)\n",
    "\n",
    "        self.numerical_mask = ~self.categorical_mask\n",
    "\n",
    "    def _compute_distance(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Compute mixed distance for one sample.\n",
    "        - Categorical distance: Hamming distance.\n",
    "        - Numerical distance: Euclidean distance.\n",
    "        \"\"\"\n",
    "\n",
    "        cat_distance = np.sum(x1[self.categorical_mask] != x2[self.categorical_mask])\n",
    "\n",
    "        num_distance = np.sqrt(\n",
    "            np.sum((x1[self.numerical_mask].astype(float) - x2[self.numerical_mask].astype(float)) ** 2)\n",
    "        )\n",
    "\n",
    "        # Combine distances\n",
    "        return cat_distance + num_distance\n",
    "\n",
    "    def _get_neighbors(self, x):\n",
    "        \"\"\"\n",
    "        Find k-nearest neighbors for a single sample.\n",
    "        \"\"\"\n",
    "        distances = [self._compute_distance(x, x_train) for x_train in self.X_train]\n",
    "        neighbors_idx = np.argsort(distances)[:self.k]\n",
    "        neighbors_distances = np.array(distances)[neighbors_idx]\n",
    "        return neighbors_idx, neighbors_distances\n",
    "\n",
    "    def _predict_single(self, x):\n",
    "        \"\"\"\n",
    "        Predict the label for a single sample using weighted voting.\n",
    "        \"\"\"\n",
    "        neighbors_idx, neighbors_distances = self._get_neighbors(x)\n",
    "        neighbor_labels = self.y_train[neighbors_idx]\n",
    "\n",
    "        weights = 1 / (neighbors_distances + 1e-5)\n",
    "        weighted_votes = {}\n",
    "        for label, weight in zip(neighbor_labels, weights):\n",
    "            weighted_votes[label] = weighted_votes.get(label, 0) + weight\n",
    "\n",
    "        return max(weighted_votes, key=weighted_votes.get)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict for the test set.\n",
    "        \"\"\"\n",
    "        X_test = np.array(X_test, dtype=object)\n",
    "        predictions = [self._predict_single(x) for x in X_test]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def predict_parallel(self, X_test, num_workers=4):\n",
    "        \"\"\"\n",
    "        Parallelize predictions across multiple CPU cores.\n",
    "        \"\"\"\n",
    "        X_test_split = np.array_split(X_test, num_workers)\n",
    "        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "            results = list(executor.map(self.predict, X_test_split))\n",
    "        return np.concatenate(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Mask: [True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "[True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "def classify_features(df):\n",
    "    categorical_mask = []\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        if len(unique_values) == 2 and set(unique_values).issubset({0, 1, 0.0, 1.0}):\n",
    "            categorical_mask.append(True)\n",
    "        elif df[column].dtype == 'object' or isinstance(unique_values[0], str):\n",
    "            categorical_mask.append(True)\n",
    "        else:\n",
    "            categorical_mask.append(False)\n",
    "    return categorical_mask\n",
    "categorical_mask = classify_features(X_test)\n",
    "\n",
    "print(\"Categorical Mask:\", categorical_mask)\n",
    "print(categorical_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNN(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(X_train_clean, y_train_clean, categorical_mask\u001b[38;5;241m=\u001b[39mcategorical_mask)\n\u001b[1;32m----> 6\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictions)\n",
      "Cell \u001b[1;32mIn [37], line 73\u001b[0m, in \u001b[0;36mKNN.predict\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03mPredict for the test set.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     72\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_test, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m---> 73\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_single(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_test]\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(predictions)\n",
      "Cell \u001b[1;32mIn [37], line 73\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03mPredict for the test set.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     72\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_test, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m---> 73\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_test]\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(predictions)\n",
      "Cell \u001b[1;32mIn [37], line 64\u001b[0m, in \u001b[0;36mKNN._predict_single\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     62\u001b[0m weighted_votes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(neighbor_labels, weights):\n\u001b[1;32m---> 64\u001b[0m     weighted_votes[label] \u001b[38;5;241m=\u001b[39m \u001b[43mweighted_votes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m weight\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(weighted_votes, key\u001b[38;5;241m=\u001b[39mweighted_votes\u001b[38;5;241m.\u001b[39mget)\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "categorical_mask = [True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
    "[True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
    "knn = KNN(k=3, metric='mixed')\n",
    "knn.fit(X_train_clean, y_train_clean, categorical_mask=categorical_mask)\n",
    "\n",
    "predictions = knn.predict(X_test)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [37], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNN(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanhattan\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m----> 3\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# accuracy = knn.evaluate(X_test, y_test)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# print(accuracy)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Dynamically determine unique classes\u001b[39;00m\n\u001b[0;32m      7\u001b[0m unique_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_test)\n",
      "Cell \u001b[1;32mIn [33], line 44\u001b[0m, in \u001b[0;36mKNN.predict\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_test):\n\u001b[0;32m     43\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_test, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 44\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_single(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_test]\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(predictions)\n",
      "Cell \u001b[1;32mIn [33], line 44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_test):\n\u001b[0;32m     43\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_test, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 44\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_test]\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(predictions)\n",
      "Cell \u001b[1;32mIn [33], line 30\u001b[0m, in \u001b[0;36mKNN._predict_single\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 30\u001b[0m     neighbors_idx, neighbors_distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     neighbor_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[neighbors_idx]\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Weighted voting\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [33], line 24\u001b[0m, in \u001b[0;36mKNN._get_neighbors\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_neighbors\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 24\u001b[0m     distances \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_distance(x, x_train) \u001b[38;5;28;01mfor\u001b[39;00m x_train \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train]\n\u001b[0;32m     25\u001b[0m     neighbors_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(distances)[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk]\n\u001b[0;32m     26\u001b[0m     neighbors_distances \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(distances)[neighbors_idx]\n",
      "Cell \u001b[1;32mIn [33], line 24\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_neighbors\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 24\u001b[0m     distances \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x_train \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train]\n\u001b[0;32m     25\u001b[0m     neighbors_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(distances)[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk]\n\u001b[0;32m     26\u001b[0m     neighbors_distances \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(distances)[neighbors_idx]\n",
      "Cell \u001b[1;32mIn [33], line 14\u001b[0m, in \u001b[0;36mKNN._compute_distance\u001b[1;34m(self, x1, x2)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_distance\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2):\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meuclidean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m:\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msum((x1 \u001b[38;5;241m-\u001b[39m x2) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanhattan\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "knn = KNN(k=5, metric='manhattan')\n",
    "knn.fit(X_train, y_train)\n",
    "preds = knn.predict(X_test)\n",
    "# accuracy = knn.evaluate(X_test, y_test)\n",
    "# print(accuracy)\n",
    "# Dynamically determine unique classes\n",
    "unique_classes = np.unique(y_test)\n",
    "target_names = [f\"Class {c}\" for c in unique_classes]\n",
    "\n",
    "# Generate detailed classification report\n",
    "report = classification_report(y_test, preds, target_names=target_names)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-19 18:43:17,359] A new study created in memory with name: no-name-fded2a58-0fbe-4d59-b5af-63dc819010f4\n",
      "[I 2024-12-19 18:43:17,374] Trial 0 finished with value: 0.8859649122807017 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'metric': 'minkowski', 'p': 2, 'algorithm': 'kd_tree', 'leaf_size': 30}. Best is trial 0 with value: 0.8859649122807017.\n",
      "[I 2024-12-19 18:43:17,390] Trial 1 finished with value: 0.9035087719298246 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'kd_tree', 'leaf_size': 10}. Best is trial 1 with value: 0.9035087719298246.\n",
      "[I 2024-12-19 18:43:17,432] Trial 2 finished with value: 0.8859649122807017 and parameters: {'n_neighbors': 16, 'weights': 'uniform', 'metric': 'minkowski', 'p': 3, 'algorithm': 'brute', 'leaf_size': 20}. Best is trial 1 with value: 0.9035087719298246.\n",
      "[I 2024-12-19 18:43:17,449] Trial 3 finished with value: 0.9122807017543859 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,457] Trial 4 finished with value: 0.9035087719298246 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'minkowski', 'p': 2, 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,472] Trial 5 finished with value: 0.9035087719298246 and parameters: {'n_neighbors': 18, 'weights': 'distance', 'metric': 'minkowski', 'p': 1, 'algorithm': 'brute', 'leaf_size': 30}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,493] Trial 6 finished with value: 0.8947368421052632 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'metric': 'minkowski', 'p': 2, 'algorithm': 'auto', 'leaf_size': 20}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,501] Trial 7 finished with value: 0.8859649122807017 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'metric': 'euclidean', 'algorithm': 'kd_tree', 'leaf_size': 50}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,509] Trial 8 finished with value: 0.868421052631579 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'metric': 'minkowski', 'p': 1, 'algorithm': 'kd_tree', 'leaf_size': 30}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,527] Trial 9 finished with value: 0.9035087719298246 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute', 'leaf_size': 20}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,549] Trial 10 finished with value: 0.8947368421052632 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'ball_tree', 'leaf_size': 40}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,580] Trial 11 finished with value: 0.9122807017543859 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 10}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,601] Trial 12 finished with value: 0.8771929824561403 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'ball_tree', 'leaf_size': 10}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,629] Trial 13 finished with value: 0.9122807017543859 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 40}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,646] Trial 14 finished with value: 0.8947368421052632 and parameters: {'n_neighbors': 13, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 40}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,691] Trial 15 finished with value: 0.8771929824561403 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'auto', 'leaf_size': 50}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,729] Trial 16 finished with value: 0.9035087719298246 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 10}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,777] Trial 17 finished with value: 0.8947368421052632 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'ball_tree', 'leaf_size': 20}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,820] Trial 18 finished with value: 0.868421052631579 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 40}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,864] Trial 19 finished with value: 0.8859649122807017 and parameters: {'n_neighbors': 20, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'auto', 'leaf_size': 10}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,893] Trial 20 finished with value: 0.9122807017543859 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 30}. Best is trial 3 with value: 0.9122807017543859.\n",
      "[I 2024-12-19 18:43:17,929] Trial 21 finished with value: 0.9210526315789473 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 40}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:17,961] Trial 22 finished with value: 0.9210526315789473 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:17,987] Trial 23 finished with value: 0.9122807017543859 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,019] Trial 24 finished with value: 0.9210526315789473 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,055] Trial 25 finished with value: 0.9035087719298246 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 40}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,086] Trial 26 finished with value: 0.9035087719298246 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,133] Trial 27 finished with value: 0.9035087719298246 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'auto', 'leaf_size': 40}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,185] Trial 28 finished with value: 0.9122807017543859 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,220] Trial 29 finished with value: 0.8947368421052632 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'kd_tree', 'leaf_size': 40}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,258] Trial 30 finished with value: 0.9210526315789473 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,286] Trial 31 finished with value: 0.9210526315789473 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,311] Trial 32 finished with value: 0.9210526315789473 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,331] Trial 33 finished with value: 0.9122807017543859 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,360] Trial 34 finished with value: 0.9035087719298246 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 40}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,384] Trial 35 finished with value: 0.9122807017543859 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'kd_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,412] Trial 36 finished with value: 0.9035087719298246 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,457] Trial 37 finished with value: 0.868421052631579 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'metric': 'minkowski', 'p': 3, 'algorithm': 'ball_tree', 'leaf_size': 40}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,477] Trial 38 finished with value: 0.9210526315789473 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,526] Trial 39 finished with value: 0.8947368421052632 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'minkowski', 'p': 3, 'algorithm': 'ball_tree', 'leaf_size': 30}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,553] Trial 40 finished with value: 0.9035087719298246 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'auto', 'leaf_size': 40}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,588] Trial 41 finished with value: 0.9210526315789473 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,626] Trial 42 finished with value: 0.9122807017543859 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,656] Trial 43 finished with value: 0.9035087719298246 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,709] Trial 44 finished with value: 0.9122807017543859 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'brute', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,740] Trial 45 finished with value: 0.8947368421052632 and parameters: {'n_neighbors': 16, 'weights': 'uniform', 'metric': 'minkowski', 'p': 1, 'algorithm': 'kd_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,765] Trial 46 finished with value: 0.9210526315789473 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 40}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,789] Trial 47 finished with value: 0.9122807017543859 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,810] Trial 48 finished with value: 0.868421052631579 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 21 with value: 0.9210526315789473.\n",
      "[I 2024-12-19 18:43:18,838] Trial 49 finished with value: 0.9035087719298246 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'metric': 'minkowski', 'p': 1, 'algorithm': 'ball_tree', 'leaf_size': 40}. Best is trial 21 with value: 0.9210526315789473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 4, 'weights': 'uniform', 'metric': 'manhattan', 'algorithm': 'ball_tree', 'leaf_size': 40}\n",
      "Best Accuracy: 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    # Suggest values for the hyperparameters\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 20)\n",
    "    metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'minkowski'])\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = KNN(\n",
    "        n_neighbors=n_neighbors,\n",
    "        metric=metric,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Return the accuracy as the objective to maximize\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')  # We want to maximize accuracy\n",
    "study.optimize(objective, n_trials=50)  # Adjust n_trials for exploration depth\n",
    "\n",
    "# Print the best parameters and accuracy\n",
    "print(\"Best Parameters:\", study.best_params)\n",
    "print(\"Best Accuracy:\", study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
